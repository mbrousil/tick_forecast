select(time, mmwrWeek, siteID, `Amblyomma americanum`)
# In case NEON makes a provisional data release during the challenge
# need to make sure that we filter out 2021 data that is in the "future"
run_date <- today()
year(run_date) <- year(run_date) - 1
run_mmwrWeek <- MMWRweek(run_date)$MMWRweek
challenge_time <- MMWRweek2Date(year(run_date), run_mmwrWeek)
tick_targets <- tick_standard %>%
filter(time < challenge_time) %>%
clean_names()
tick_field
tick_field_raw
tick_taxon_raw
neon_index()
?neon_index
tick_field_raw <- neon_read("tck_fielddata-basic", keep_filename = TRUE, files = "")
tick_field_raw
neon_read("tck_fielddata-basic", keep_filename = TRUE, files = ".")
?neon_read
neon_index()[, "path"]
tick_field_raw <- neon_read("tck_fielddata-basic",
keep_filename = TRUE,
files = neon_index()[, "path"])
neon_dir()
tick_field_raw <- neon_read("tck_fielddata-basic",
keep_filename = TRUE,
dir = neon_dir())
tick_field_raw
# Check for neonstore package and install if needed
if(!"neonstore" %in% installed.packages()){
remotes::install_github("cboettig/neonstore", ref = "patch/api-updates")
}
library(tidyverse) # for data wrangling and piping (dplyr probably ok)
library(lubridate) # for finding year from dates
library(stringr) # for searching within character strings
library(parallel) # for using more than one core in download
library(MMWRweek) # for converting from date to MMWR week
library(janitor)
library(neonstore)
# Select target species and life stage
target_species <- "Amblyomma americanum"
target_lifestage <- "Nymph"
target_sites <- c("BLAN", "KONZ", "LENO", "ORNL", "OSBS", "SCBI",
"SERC", "TALL", "UKFS")
Sys.setenv("NEONSTORE_HOME" = "/neonstore")
Sys.setenv("NEONSTORE_DB" = "/neonstore")
# Get data from NEON
product <- "DP1.10093.001"
neon_download(product = product,
site = target_sites)
tick_field_raw <- neon_read("tck_fielddata-basic", keep_filename = TRUE)
tick_taxon_raw <- neon_read("tck_taxonomyProcessed-basic")
tick_field_raw
tick_taxon_raw
# There are lots of reasons why sampling didn't occur (logistics, too wet, too cold, etc.)
# so, keep records when sampling occurred
tick_field <- tick_field_raw %>%
filter(totalSampledArea > 0) %>%
mutate(time = floor_date(collectDate, unit = "day")) %>%
unite(namedLocation, time, col = "occasionID", sep = "_")
# Combine adults into single category and make wide to get zero counts
tick_taxon_wide <- tick_taxon_raw %>%
filter(sampleCondition == "OK") %>% # remove taxonomy samples with quality issues
mutate(sexOrAge = if_else(sexOrAge == "Female" | sexOrAge == "Male",
"Adult",     # convert to Adult
sexOrAge),
time = floor_date(collectDate, unit = "day")) %>%
unite(namedLocation, time, col = "occasionID", sep = "_") %>%
pivot_wider(id_cols = occasionID, # make wide by species and life stage
names_from = c(acceptedTaxonID, sexOrAge),
values_from = individualCount,
names_sep = "_",
# duplicates occur because of Adults that where F/M - add them
values_fn = {sum},
values_fill = 0)
tick_field
tick_taxon_wide
# Join taxonomy and field data
tick_joined <- left_join(tick_taxon_wide, tick_field, by = "occasionID") %>%
select(-NA_NA, -geodeticDatum, -samplingImpractical, -targetTaxaPresent,
-adultCount, -nymphCount, -larvaCount, -samplingProtocolVersion,
-measuredBy, -sampleCode, -biophysicalCriteria, -plotType)
tick_joined
# Get matching taxon ids
taxon_ids <- tick_taxon_raw %>%
filter(!is.na(acceptedTaxonID)) %>%
select(acceptedTaxonID, scientificName, taxonRank) %>%
distinct()
# Pivot to long version
tick_long <- tick_joined %>%
pivot_longer(cols = all_of(spp_cols),
names_to = "taxonAge",
values_to = "processedCount",
values_drop_na = TRUE) %>%
separate(col = taxonAge, into = c("acceptedTaxonID", "lifeStage"), sep = "_")
# All the species column names
spp_cols <- tick_joined %>%
select(contains("Larva"), contains("Nymph"), contains("Adult")) %>%
colnames()
# Pivot to long version
tick_long <- tick_joined %>%
pivot_longer(cols = all_of(spp_cols),
names_to = "taxonAge",
values_to = "processedCount",
values_drop_na = TRUE) %>%
separate(col = taxonAge, into = c("acceptedTaxonID", "lifeStage"), sep = "_")
# Add taxon ids
tick_long <- left_join(tick_long, taxon_ids, by = "acceptedTaxonID")
tick_long
# Standardize the data and subset to targets
tick_standard <- tick_long %>%
filter(siteID %in% target_sites, # sites we want
lifeStage == target_lifestage, # life stage we want
scientificName == target_species, # species we want
grepl("Forest", nlcdClass)) %>%  # forest plots
mutate(date = floor_date(collectDate, unit = "day"),
date = ymd(date),
year = year(date),
mmwrWeek = MMWRweek(date)$MMWRweek,
time = MMWRweek2Date(year, mmwrWeek)) %>%
select(time, processedCount, totalSampledArea, siteID) %>%
mutate(totalSampledArea = as.numeric(totalSampledArea)) %>%
group_by(siteID, time) %>%
summarise(totalCount = sum(processedCount), # all counts in a week
totalArea = sum(totalSampledArea),# total area surveyed in a week
`Amblyomma americanum` = totalCount / totalArea * 1600) %>% # scale to the size of a plot
mutate(mmwrWeek = MMWRweek(time)$MMWRweek) %>%
arrange(siteID, time) %>%
filter() %>%
select(time, mmwrWeek, siteID, `Amblyomma americanum`)
tick_standard
tick_long %>%
filter(siteID %in% target_sites, # sites we want
lifeStage == target_lifestage, # life stage we want
scientificName == target_species, # species we want
grepl("Forest", nlcdClass)) %>%  # forest plots
mutate(date = floor_date(collectDate, unit = "day"),
date = ymd(date),
year = year(date),
mmwrWeek = MMWRweek(date)$MMWRweek,
time = MMWRweek2Date(year, mmwrWeek)) %>%
select(time, processedCount, totalSampledArea, siteID) %>%
mutate(totalSampledArea = as.numeric(totalSampledArea)) %>%
group_by(siteID, time) %>%
summarise(totalCount = sum(processedCount), # all counts in a week
totalArea = sum(totalSampledArea),# total area surveyed in a week
`Amblyomma americanum` = totalCount / totalArea * 1600) %>% # scale to the size of a plot
mutate(mmwrWeek = MMWRweek(time)$MMWRweek) %>%
arrange(siteID, time) %>%
filter()
tick_long %>%
filter(siteID %in% target_sites, # sites we want
lifeStage == target_lifestage, # life stage we want
scientificName == target_species, # species we want
grepl("Forest", nlcdClass)) %>%  # forest plots
mutate(date = floor_date(collectDate, unit = "day"),
date = ymd(date),
year = year(date),
mmwrWeek = MMWRweek(date)$MMWRweek,
time = MMWRweek2Date(year, mmwrWeek)) %>%
select(time, processedCount, totalSampledArea, siteID) %>%
mutate(totalSampledArea = as.numeric(totalSampledArea))
# Standardize the data and subset to targets
tick_standard <- tick_long %>%
filter(siteID %in% target_sites, # sites we want
lifeStage == target_lifestage, # life stage we want
scientificName == target_species, # species we want
grepl("Forest", nlcdClass)) %>%  # forest plots
mutate(date = floor_date(collectDate, unit = "day"),
date = ymd(date),
year = year(date),
mmwrWeek = MMWRweek(date)$MMWRweek,
time = MMWRweek2Date(year, mmwrWeek)) %>%
select(time, processedCount, totalSampledArea, siteID) %>%
mutate(totalSampledArea = as.numeric(totalSampledArea)) %>%
group_by(siteID, time) %>%
summarise(totalCount = sum(processedCount), # all counts in a week
totalArea = sum(totalSampledArea),# total area surveyed in a week
amblyomma_americanum = totalCount / totalArea * 1600) %>% # scale to the size of a plot
mutate(mmwrWeek = MMWRweek(time)$MMWRweek) %>%
arrange(siteID, time) %>%
filter() %>%
select(time, mmwrWeek, siteID, amblyomma_americanum)
tick_standard
# In case NEON makes a provisional data release during the challenge
# need to make sure that we filter out 2021 data that is in the "future"
run_date <- today()
year(run_date) <- year(run_date) - 1
run_mmwrWeek <- MMWRweek(run_date)$MMWRweek
challenge_time <- MMWRweek2Date(year(run_date), run_mmwrWeek)
tick_targets <- tick_standard %>%
filter(time < challenge_time)
tick_targets
read_csv("https://data.ecoforecast.org/targets/ticks/ticks-targets.csv.gz",
guess_max = 1e6)
read_csv("https://data.ecoforecast.org/targets/ticks/ticks-targets.csv.gz",
guess_max = 1e6) %>%
pull(amblyomma_americanum)
tick_targets
tick_targets %>%
mutate(epi_week = epiweek(time))
?MMWRweek
tick_field_raw
tick_field_raw %>%
View()
?floor_date
?yday
yday("2024-12-31")
tick_targets <- tick_standard %>%
filter(time < challenge_time) %>%
mutate(year = year(time),
day_num = yday(time))
tick_targets
tick_targets <- tick_standard %>%
filter(time < challenge_time) %>%
mutate(year = year(time),
day_num = yday(time)) %>%
select(site_id = siteID, mmwr_week = mmwrWeek, time, year, day_num, amblyomma_americanum)
tick_targets
# Write targets to csv
write_csv(tick_targets,
file = "data/ticks_target.csv")
# Write targets to csv
write_csv(tick_targets,
file = "data/ticks_target.csv")
tick_targets
library(tidyverse)
library(sf)
neon_sites <- read_csv(file = "data/Ticks_NEON_Field_Site_Metadata_20210928.csv")
neon_sites
neon_sites
neon_sites_sf <- neon_sites %>%
select(field_domain_id, field_site_id, field_site_name, field_site_state,
field_latitude, field_longitude) %>%
st_as_sf(x = .,
coords = c(field_longitude, field_latitude),
# WGS84
crs = 4326)
neon_sites_sf <- neon_sites %>%
dplyr::select(field_domain_id, field_site_id, field_site_name, field_site_state,
field_latitude, field_longitude) %>%
st_as_sf(x = .,
coords = c(field_longitude, field_latitude),
# WGS84
crs = 4326)
neon_sites %>%
select(field_domain_id, field_site_id, field_site_name, field_site_state,
field_latitude, field_longitude)
neon_sites_sf <- neon_sites %>%
select(field_domain_id, field_site_id, field_site_name, field_site_state,
field_latitude, field_longitude) %>%
st_as_sf(x = .,
coords = c("field_longitude", "field_latitude"),
# WGS84
crs = 4326)
neon_sites_sf
library(rnaturalearth)
# State polygons in sf format
state_shapes <- ne_states(country = "United States of America",
returnclass = "sf")
ggplot() +
geom_sf(data = state_shapes) +
geom_sf(data = neon_sites_sf)
neon_sites_sf
library(ggrepel)
ggplot() +
geom_sf(data = state_shapes) +
geom_sf(data = neon_sites_sf) +
geom_label_repel(
data = neon_sites_sf,
aes(label = field_site_id, geometry = geometry),
stat = "sf_coordinates",
min.segment.length = 0,
nudge_y = 2,
nudge_x = 2,
color = "black")
ggplot() +
geom_sf(data = state_shapes) +
geom_sf(data = neon_sites_sf) +
geom_label_repel(
data = neon_sites_sf,
aes(label = field_site_id, geometry = geometry),
stat = "sf_coordinates",
min.segment.length = 0,
nudge_y = 2,
nudge_x = 2,
color = "black") +
coord_sf(xlim = c(-100, -65), ylim = c(30, 50))
ggplot() +
geom_sf(data = state_shapes) +
geom_sf(data = neon_sites_sf) +
geom_label_repel(
data = neon_sites_sf,
aes(label = field_site_id, geometry = geometry),
stat = "sf_coordinates",
min.segment.length = 0,
nudge_y = 2,
nudge_x = 2,
color = "black") +
coord_sf(xlim = c(-100, -65), ylim = c(30, 50)) +
xlab("Longitude") +
ylab("Latitude") +
theme_bw()
ggplot() +
geom_sf(data = state_shapes) +
geom_sf(data = neon_sites_sf) +
geom_label_repel(
data = neon_sites_sf,
aes(label = field_site_id, geometry = geometry),
stat = "sf_coordinates",
min.segment.length = 0,
nudge_y = 2,
nudge_x = 2,
color = "black") +
coord_sf(xlim = c(-100, -65), ylim = c(28, 50)) +
xlab("Longitude") +
ylab("Latitude") +
theme_bw()
ggplot() +
geom_sf(data = state_shapes) +
geom_sf(data = neon_sites_sf) +
geom_label_repel(
data = neon_sites_sf,
aes(label = field_site_id, geometry = geometry),
stat = "sf_coordinates",
min.segment.length = 0,
nudge_y = 2,
nudge_x = 2,
color = "black") +
coord_sf(xlim = c(-100, -70), ylim = c(28, 50)) +
xlab("Longitude") +
ylab("Latitude") +
theme_bw()
site_map <- ggplot() +
geom_sf(data = state_shapes) +
geom_sf(data = neon_sites_sf) +
geom_label_repel(
data = neon_sites_sf,
aes(label = field_site_id, geometry = geometry),
stat = "sf_coordinates",
min.segment.length = 0,
nudge_y = 2,
nudge_x = 2,
color = "black") +
coord_sf(xlim = c(-100, -70), ylim = c(28, 50)) +
xlab("Longitude") +
ylab("Latitude") +
theme_bw() +
theme(panel.background = element_rect(fill = "oceanblue"))
site_map
ggplot() +
geom_sf(data = state_shapes) +
geom_sf(data = neon_sites_sf) +
geom_label_repel(
data = neon_sites_sf,
aes(label = field_site_id, geometry = geometry),
stat = "sf_coordinates",
min.segment.length = 0,
nudge_y = 2,
nudge_x = 2,
color = "black") +
coord_sf(xlim = c(-100, -70), ylim = c(28, 50)) +
xlab("Longitude") +
ylab("Latitude") +
theme_bw() +
theme(panel.background = element_rect(fill = "lightblue2"))
ggplot() +
geom_sf(data = state_shapes) +
geom_sf(data = neon_sites_sf) +
geom_label_repel(
data = neon_sites_sf,
aes(label = field_site_id, geometry = geometry),
stat = "sf_coordinates",
min.segment.length = 0,
nudge_y = 2,
nudge_x = 2,
color = "black") +
coord_sf(xlim = c(-100, -70), ylim = c(28, 50)) +
xlab("Longitude") +
ylab("Latitude") +
theme_bw() +
theme(panel.background = element_rect(fill = "lightblue"))
ggplot() +
geom_sf(data = state_shapes) +
geom_sf(data = neon_sites_sf) +
geom_label_repel(
data = neon_sites_sf,
aes(label = field_site_id, geometry = geometry),
stat = "sf_coordinates",
min.segment.length = 0,
nudge_y = 2,
nudge_x = 2,
color = "black") +
coord_sf(xlim = c(-100, -70), ylim = c(28, 50)) +
xlab("Longitude") +
ylab("Latitude") +
theme_bw() +
theme(panel.background = element_rect(fill = "lightblue"),
panel.grid = element_blank())
ggplot() +
geom_sf(data = state_shapes) +
geom_sf(data = neon_sites_sf) +
geom_label_repel(
data = neon_sites_sf,
aes(label = field_site_id, geometry = geometry),
stat = "sf_coordinates",
min.segment.length = 0,
nudge_y = 2,
nudge_x = 2,
color = "black") +
coord_sf(xlim = c(-100, -70), ylim = c(28, 50)) +
xlab("Longitude") +
ylab("Latitude") +
theme_bw()
site_map <- ggplot() +
geom_sf(data = state_shapes) +
geom_sf(data = neon_sites_sf) +
geom_label_repel(
data = neon_sites_sf,
aes(label = field_site_id, geometry = geometry),
stat = "sf_coordinates",
min.segment.length = 0,
nudge_y = 2,
nudge_x = 2,
color = "black") +
coord_sf(xlim = c(-100, -70), ylim = c(28, 50)) +
xlab("Longitude") +
ylab("Latitude") +
theme_bw()
ggsave(filename = "figures/site_overview_map.png", plot = site_map,
device = "png", width = 6, height = 4, units = "in")
site_map <- ggplot() +
geom_sf(data = state_shapes) +
geom_sf(data = neon_sites_sf) +
geom_label_repel(
data = neon_sites_sf,
aes(label = field_site_id, geometry = geometry),
stat = "sf_coordinates",
min.segment.length = 0,
nudge_y = 2,
nudge_x = 2,
color = "black") +
coord_sf(xlim = c(-100, -65), ylim = c(30, 50)) +
xlab("Longitude") +
ylab("Latitude") +
theme_bw()
ggsave(filename = "figures/site_overview_map.png", plot = site_map,
device = "png", width = 6, height = 4, units = "in")
site_map <- ggplot() +
geom_sf(data = state_shapes) +
geom_sf(data = neon_sites_sf) +
geom_label_repel(
data = neon_sites_sf,
aes(label = field_site_id, geometry = geometry),
stat = "sf_coordinates",
min.segment.length = 0,
nudge_y = 2,
nudge_x = 2,
color = "black") +
coord_sf(xlim = c(-105, -70), ylim = c(28, 48)) +
xlab("Longitude") +
ylab("Latitude") +
theme_bw()
ggsave(filename = "figures/site_overview_map.png", plot = site_map,
device = "png", width = 6, height = 4, units = "in")
ggplot() +
geom_sf(data = state_shapes) +
geom_sf(data = neon_sites_sf) +
geom_label_repel(
data = neon_sites_sf,
aes(label = field_site_id, geometry = geometry),
stat = "sf_coordinates",
min.segment.length = 0,
nudge_y = 2,
nudge_x = 2,
color = "red") +
coord_sf(xlim = c(-105, -70), ylim = c(28, 48)) +
xlab("Longitude") +
ylab("Latitude") +
theme_bw()
ggplot() +
geom_sf(data = state_shapes) +
geom_sf(data = neon_sites_sf, color = "red") +
geom_label_repel(
data = neon_sites_sf,
aes(label = field_site_id, geometry = geometry),
stat = "sf_coordinates",
min.segment.length = 0,
nudge_y = 2,
nudge_x = 2,
color = "black") +
coord_sf(xlim = c(-105, -70), ylim = c(28, 48)) +
xlab("Longitude") +
ylab("Latitude") +
theme_bw()
site_map <- ggplot() +
geom_sf(data = state_shapes) +
geom_sf(data = neon_sites_sf, color = "red") +
geom_label_repel(
data = neon_sites_sf,
aes(label = field_site_id, geometry = geometry),
stat = "sf_coordinates",
min.segment.length = 0,
nudge_y = 2,
nudge_x = 2,
color = "black") +
coord_sf(xlim = c(-105, -70), ylim = c(28, 48)) +
xlab("Longitude") +
ylab("Latitude") +
theme_bw()
ggsave(filename = "figures/site_overview_map.png", plot = site_map,
device = "png", width = 6, height = 4, units = "in")
